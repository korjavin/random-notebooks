{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### The other day I was listening to [Linear Digressions podcast](http://lineardigressions.com/) and they were talking about a tool to visualize numerical features called Chernoff faces ([episode](http://lineardigressions.com/episodes/2016/2/29/chernoff-faces-and-minard-maps)). I wanted to give it a try in this dataset just for fun.\n\n### What are Chernoff faces?\n#### Chernoff faces, invented by Herman Chernoff in 1973, display multivariate data in the shape of a human face. The individual parts, such as eyes, ears, mouth and nose represent values of the variables by their shape, size, placement and orientation. The idea behind using faces is that humans easily recognize faces and notice small changes without difficulty. Chernoff faces handle each variable differently. Because the features of the faces vary in perceived importance, the way in which variables are mapped to the features should be carefully chosen (e.g. eye size and eyebrow-slant have been found to carry significant weight) ([paper]( http://www.research.ibm.com/people/c/cjmorris/publications/Chernoff_990402.pdf)). Following is an example for the famous iris dataset ([source](https://archive.ics.uci.edu/ml/datasets/iris)) where features (sepal length, sepal width, petal length, petal width) are presented as Chernoff faces and the colour marks each of the species (i.e. the target: setosa, versicolor, virginica) ([source](https://github.com/antononcube/MathematicaForPrediction/blob/master/MarkdownDocuments/Making-Chernoff-faces-for-data-visualization.md)):\n\n![Chernoff faces](https://camo.githubusercontent.com/ced6cd0923a923aade542c33f9ccc86614049e30ab7c0c1085ee7823752ce858/687474703a2f2f692e696d6775722e636f6d2f7550425a4a75666c2e676966)\n\n#### It can be seen that different species have different characteristic facial features that let their indentification visually very easily.\n#### Let's take a look now at how the Chernoff faces look like for the numerical features of this competition and whether the resultant faces can help to discriminate the target classes in some way.","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T22:16:46.349176Z","iopub.execute_input":"2022-01-24T22:16:46.349996Z","iopub.status.idle":"2022-01-24T22:16:46.35522Z","shell.execute_reply.started":"2022-01-24T22:16:46.349793Z","shell.execute_reply":"2022-01-24T22:16:46.354194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-07T17:39:08.755598Z","iopub.execute_input":"2022-01-07T17:39:08.756211Z","iopub.status.idle":"2022-01-07T17:39:08.778782Z","shell.execute_reply.started":"2022-01-07T17:39:08.756164Z","shell.execute_reply":"2022-01-07T17:39:08.77775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Мы хотим нормализацию что бы значения от 0 до 100 оказывали сильное вли","metadata":{}},{"cell_type":"code","source":"x = np.linspace(1, 500)\nmax=np.pi/2\nplt.plot(x, np.arctan(x/30)/max)\nplt.show()\n\n#np.arctan(2/10)/max/2","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:17:05.141577Z","iopub.execute_input":"2022-01-24T22:17:05.142023Z","iopub.status.idle":"2022-01-24T22:17:05.310577Z","shell.execute_reply.started":"2022-01-24T22:17:05.141985Z","shell.execute_reply":"2022-01-24T22:17:05.309739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to draw Chernoff faces (source: https://gist.github.com/dribnet/e26f52f423f0656c1bb8fc6f4e741cc2#file-mpl_cfaces-py)\n\ndef cface(ax, x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18):\n    # x1 = height  of upper face\n    # x2 = overlap of lower face\n    # x3 = half of vertical size of face\n    # x4 = width of upper face\n    # x5 = width of lower face\n    # x6 = length of nose\n    # x7 = vertical position of mouth\n    # x8 = curvature of mouth\n    # x9 = width of mouth\n    # x10 = vertical position of eyes\n    # x11 = separation of eyes\n    # x12 = slant of eyes\n    # x13 = eccentricity of eyes\n    # x14 = size of eyes\n    # x15 = position of pupils\n    # x16 = vertical position of eyebrows\n    # x17 = slant of eyebrows\n    # x18 = size of eyebrows\n    \n    # transform some values so that input between 0,1 yields variety of output\n    \n    x3 = 1.9*(x3-.5)\n    x4 = (x4+.25)\n    x5 = (x5+.2)\n    x6 = .3*(x6+.01)\n    x8 = 5*(x8+.001)\n    x11 /= 5\n    x12 = 2*(x12-.5)\n    x13 += .05\n    x14 += .1\n    x15 = .5 *(x15-.5)\n    x16 = .25*x16\n    x17 = .5*(x17-.5)\n    x18 = .9*(x18+.1)\n\n    # top of face, in box with l=-x4, r=x4, t=x1, b=x3\n    e = matplotlib.patches.Ellipse( (0,(x1+x3)/2), 2*x4, (x1-x3), fc='white', edgecolor='black', linewidth=2)\n    #e.set_clip_box(ax.bbox)\n    #e.set_facecolor([0,0,0])\n    ax.add_artist(e)\n\n    # bottom of face, in box with l=-x5, r=x5, b=-x1, t=x2+x3\n    e = matplotlib.patches.Ellipse( (0,(-x1+x2+x3)/2), 2*x5, (x1+x2+x3), fc='white', edgecolor='black', linewidth=2)\n    ax.add_artist(e)\n\n    # cover overlaps\n    e = matplotlib.patches.Ellipse( (0,(x1+x3)/2), 2*x4, (x1-x3), fc='white', edgecolor='black', ec='none')\n    ax.add_artist(e)\n    e = matplotlib.patches.Ellipse( (0,(-x1+x2+x3)/2), 2*x5, (x1+x2+x3), fc='white', edgecolor='black', ec='none')\n    ax.add_artist(e)\n    \n    # draw nose\n    ax.plot([0,0], [-x6/2, x6/2], 'b', lw =5)\n    \n    # draw mouth\n    p = matplotlib.patches.Arc( (0,-x7+.5/x8), 1/x8, 1/x8, theta1=270-180/np.pi*np.arctan(x8*x9), theta2=270+180/np.pi*np.arctan(x8*x9), lw=5)\n    ax.add_artist(p)\n    \n    # draw eyes\n    p = matplotlib.patches.Ellipse( (-x11-x14/2,x10), x14, x13*x14, angle=-180/np.pi*x12, facecolor='m', edgecolor='m')\n    ax.add_artist(p)\n    #ax.fill_between( -x11-x14/2,x10, \"red\")       \n    p = matplotlib.patches.Ellipse( (x11+x14/2,x10), x14, x13*x14, angle=180/np.pi*x12, facecolor='m', edgecolor='m')\n    ax.add_artist(p)\n\n    # draw pupils\n    p = matplotlib.patches.Ellipse( (-x11-x14/2-x15*x14/2, x10), .09, .09, facecolor='g')\n    ax.add_artist(p)\n    p = matplotlib.patches.Ellipse( (x11+x14/2-x15*x14/2, x10), .09, .09, facecolor='g')\n    ax.add_artist(p)\n    \n    # draw eyebrows\n    #ax.plot([-x11-x14/2-x14*x18/2,-x11-x14/2+x14*x18/2],[x10+x13*x14*(x16+x17)+0.1,x10+x13*x14*(x16-x17)+0.1],'r', lw=3)\n    #ax.plot([x11+x14/2+x14*x18/2,x11+x14/2-x14*x18/2],[x10+x13*x14*(x16+x17)+0.1,x10+x13*x14*(x16-x17)+0.1],'r', lw=3)\n\n# тут наши данные\n!rm -rf img\n!mkdir -p img\n\n#cface(ax,  0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1 )\n# [0,1,2,3,5,8,9,10,11,12,15] - most significant columns\nsites=[ \"Amazoncom\", \"Grocerywalmartcom\", \"Instacartcom\", \"Walmartcom\", \"Petcocom\", \"Meijercom\", \"Targetcom\", \"Homedepotcom\", \"Chewycom\", \"Petsmartcom\", \"Krogercom\"]\nvalues = [ 0, 0, 0, 0,0, 0, 0, 0, 0, 0, 0 ]\n\nreport = {}\ni=0\nfor task in sites:\n    report[task] = values[i]\n    i=i+1\n    \nmax_listing=500\n    \nnorm_report={}\n\ndefault_val_1=0.5\n\nfor default_val in np.linspace(0.62, 1, num=5):\n#real data\n    max=np.pi\n    fig = plt.figure()\n    ax = fig.add_subplot(1,1,1,aspect='equal')\n\n    for site, num  in report.items():\n      norm_report[site]=default_val+np.arctan(num/20)/max\n        \n   \n    columns = [0,1,2,3,5,8,9,10,11,12,15] \n    iter=0\n    face_values= [default_val_1] * 18\n    for site, num in norm_report.items():\n        face_values[columns[iter]]=num\n        iter=iter+1\n\n\n\n    cface(ax,*face_values)\n    ax.axis([-1.2,1.2,-1.2,1.2])\n    ax.set_facecolor('xkcd:turquoise')\n\n    ax.set_xticks([])\n    ax.set_yticks([])\n    fig.subplots_adjust(hspace=0, wspace=0)\n    #fig.text(0,0,default_val)\n    plt.savefig('img/predicted' + str(default_val) + '.png', bbox_inches='tight')\n#norm_report\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T22:17:29.912149Z","iopub.execute_input":"2022-01-24T22:17:29.912682Z","iopub.status.idle":"2022-01-24T22:17:32.226333Z","shell.execute_reply.started":"2022-01-24T22:17:29.912649Z","shell.execute_reply":"2022-01-24T22:17:32.225376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip  /kaggle/working/work.zip /kaggle/working/img/*","metadata":{"execution":{"iopub.status.busy":"2022-01-07T17:56:36.740726Z","iopub.execute_input":"2022-01-07T17:56:36.74108Z","iopub.status.idle":"2022-01-07T17:56:37.516834Z","shell.execute_reply.started":"2022-01-07T17:56:36.741048Z","shell.execute_reply":"2022-01-07T17:56:37.51551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import io\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T17:33:10.493183Z","iopub.execute_input":"2022-01-07T17:33:10.493643Z","iopub.status.idle":"2022-01-07T17:33:10.49906Z","shell.execute_reply.started":"2022-01-07T17:33:10.493598Z","shell.execute_reply":"2022-01-07T17:33:10.498147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buf = io.BytesIO()\nfig.savefig(buf)\nbuf.seek(0)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-07T17:33:10.500738Z","iopub.execute_input":"2022-01-07T17:33:10.50111Z","iopub.status.idle":"2022-01-07T17:33:10.536807Z","shell.execute_reply.started":"2022-01-07T17:33:10.50108Z","shell.execute_reply":"2022-01-07T17:33:10.535954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trfig, ax = plt.subplots(1,1, figsize=(20,15))\n\nfor i in range(1):\n    for j in range(1):\n        if j < 5:\n            cface(ax[i,j], .9, *cf_zeros[np.random.randint(cf_zeros.shape[0]),:])\n            ax[i,j].set_facecolor('xkcd:salmon')\n        else:\n            cface(ax[i,j], .9, *cf_ones[np.random.randint(cf_ones.shape[0]),:])\n            ax[i,j].set_facecolor('xkcd:turquoise')\n        ax[i,j].axis([-1.2, 1.2, -1.2, 1.2])\n        ax[i,j].set_xticks([])\n        ax[i,j].set_yticks([])","metadata":{"execution":{"iopub.status.busy":"2022-01-07T17:33:30.627516Z","iopub.status.idle":"2022-01-07T17:33:30.628012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### I leave it to you to find the characteristic facial features (if any) of each class!","metadata":{}}]}